---
layout:     post
title:      ScrapAndPIC
subtitle:   ScrapAndPIC
date:       2018-01-08
author:     王赛赛
header-img: img/post-bg-miui6.jpg
catalog: true
tags:
    - 闲
    - 爬虫
---

[github上](https://github.com/)看到一篇有意思的文章，用图片代替像素点合成图片。

## 图片集获取 ##

图片来自：[www.acg.fi](http://www.acg.fi)

采用爬虫获取jpg图片url共计12460条:

[http://oyug2kd6x.bkt.clouddn.com//xian2/url.txt](http://oyug2kd6x.bkt.clouddn.com//xian2/url.txt)

排除编码错误与失效链接，剩余5863条。

```python
#爬虫核心
r = requests.get("http://www.acg.fi/sitemap", headers=headers1)
r.encoding = "utf-8"
Soup = BeautifulSoup(r.text, "lxml")
for l in Soup.body.contents[7].find_all("li"):
    url_in = l.a["href"]
    print(url_in)
    r2 = requests.get(url_in, headers=headers2)
    r2.encoding = "utf-8"
    Soup2 = BeautifulSoup(r2.text, "lxml")
    for item in Soup2.find_all(class_="fancybox"):
        imgurl = item.contents[0]["src"]
        imgurl = imgurl.replace("!origin", "")
        print(imgurl)
        if "jpg" in imgurl:
            count += 1
            li.append(imgurl)
        else:
            pass
        if Soup2.find_all(class_="fancybox") == []:
            for item in Soup2.find_all(class_="aligncenter"):
                imgurl = item[0]["src"]
                imgurl = imgurl.replace("!origin", "")
                print(imgurl)
                if "jpg" in imgurl:
                    count += 1
                    li.append(imgurl)
```

下载

```python
#开5个线程下载，仍服务器上耗时3小时左右下载完
class myThread(threading.Thread):
    def __init__(self, name, q):
        threading.Thread.__init__(self)
        self.name = name
        self.q = q

    def run(self):
        print("Starting " + self.name + str(self.q.qsize()))
        while True:
            try:
                crawler(self.name, self.q)
            except:
                break
        print("Exiting " + self.name)


def crawler(threadName, q):
    url = q.get(timeout=2)
    try:
        imageSave(url)
    except Exception as e:
        print(q.qsize(), threadName, url, 'Error: ', e)

def imageSave(item, path = ""):
    filename = item.replace("/","")
    filename = filename.replace(":","")
    filename = filename[-30:]
    path = os.getcwd()  + '/img2/' + filename
    maxsize = 512
    req = urllib.request.Request(item)
    req.add_header("User-Agent",
                   "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_13_1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/63.0.3239.108 Safari/537.36")
    req.add_header("GET", item)
    req.add_header("Host", "img.gov.com.de")
    req.add_header("Referer", item)
    try:
        res = urllib.request.urlopen(req, timeout=30).read()
        image = np.asarray(bytearray(res), dtype="uint8")
        image = cv2.imdecode(image, cv2.IMREAD_COLOR)
        height, width = image.shape[:2]
        if height > width:
            scalefactor = (maxsize * 1.0) / width
            res = cv2.resize(image, (int(width * scalefactor), (int(height * scalefactor))),
                             interpolation=cv2.INTER_CUBIC)
            cutImage = res[0:maxsize, 0:maxsize]
        if width >= height:
            scalefactor = (maxsize * 1.0) / height
            res = cv2.resize(image, (int(width * scalefactor), int(height * scalefactor)),
                             interpolation=cv2.INTER_CUBIC)
            center_x = int(round(width * scalefactor * 0.5))
            cutImage = res[0:maxsize, int(center_x - maxsize / 2):int(center_x + maxsize / 2)]
        cv2.imwrite(path, cutImage)
        print('image is save in ' + path)
    except urllib.error.HTTPError as e:
        print(e.code)
    except (IncompleteRead) as e:
        print(e.code)
    except urllib.error.URLError:
        print('URLError:%s' % item)

```

结果如下：

![](http://oyug2kd6x.bkt.clouddn.com//xian%282%29pic.jpg)

## 基于HSV空间的颜色相似度选择图片 ##

Coede reference from[https://github.com/ThomasHuai](https://github.com/ThomasHuai)
```python 
def get_avg_color(img):

    width, height = img.size
    pixels = img.load()
    if type(pixels) is not int:
        data = []
        for x in range(width):
            for y in range(height):
                cpixel = pixels[x, y]
                data.append(cpixel)
        h = 0
        s = 0
        v = 0
        count = 0
        for x in range(len(data)):

            r = data[x][0]
            g = data[x][1]
            b = data[x][2]
            count += 1

            hsv = rgb_to_hsv(r / 255.0,g / 255.0,b / 255.0)
            h += hsv[0]
            s += hsv[1]
            v += hsv[2]

        hAvg = round(h / count,3)
        sAvg = round(s / count,3)
        vAvg = round(v / count,3)

        if count > 0:
            return (hAvg,sAvg,vAvg)
        else:
            print("读取图片数据失败")
    else:
        print("PIL 读取图片数据失败,请更换图片,欢迎提供解决方案")


def find_closiest(color, list_colors):
    diff = 1000
    cur_closer = False
    arr_len = 0
    for cur_color in list_colors:
        n_diff = math.sqrt(math.pow(math.fabs(color[0]-cur_color[0]), 2) + math.pow(math.fabs(color[1]-cur_color[1]), 2) + math.pow(math.fabs(color[2]-cur_color[2]), 2))
        if n_diff < diff and cur_color[3] <= REPATE:
            diff = n_diff
            cur_closer = cur_color
    if not cur_closer:
        print("没有足够的近似图片，建议设置重复")
    cur_closer[3] += 1
    return "({}, {}, {})".format(cur_closer[0],cur_closer[1],cur_closer[2])


def make_puzzle(img, color_list):
    width, height = img.size
    print("Width = {}, Height = {}".format(width,height))
    background = Image.new('RGB', img.size, (255,255,255))
    total_images = math.floor((width * height) / (SLICE_SIZE * SLICE_SIZE))
    now_images = 0
    for y1 in range(0, height, SLICE_SIZE):
        for x1 in range(0, width, SLICE_SIZE):
            y2 = y1 + SLICE_SIZE
            x2 = x1 + SLICE_SIZE

            new_img = img.crop((x1, y1, x2, y2))

            color = get_avg_color(new_img)
            close_img_name = find_closiest(color, color_list)
            close_img_name = OUT_DIR + str(close_img_name) + '.jpg'
            paste_img = Image.open(close_img_name)
            now_images += 1
            now_done = math.floor((now_images/total_images)*100)
            r = '\r[{}{}]{}%'.format("#"*now_done," "*(100 - now_done),now_done)
            sys.stdout.write(r)                          
            sys.stdout.flush()    
            background.paste(paste_img, (x1, y1))
    return background


def get_image_paths():
    paths = []
    for file_ in os.listdir(IN_DIR):
        paths.append(IN_DIR + file_)
    if len(paths) > 0:
        print("一共找到了%s" % len(paths) + "张图片")
    else:
        print("未找到任何图片")

    return paths 

def resize_pic(in_name,size):

    img = Image.open(in_name)
    img = ImageOps.fit(img, (size, size), Image.ANTIALIAS)
    return img

def convert_image(path):
    img = resize_pic(path,SLICE_SIZE)
    color = get_avg_color(img)
    img.save(str(OUT_DIR) + str(color) + ".jpg")


def convert_all_images():
    paths = get_image_paths()
    print("正在生成马赛克块...")
    pool = Pool()
    pool.map(convert_image, paths)
    pool.close()
    pool.join()   

def read_img_db():
    img_db = []
    for file_ in os.listdir(OUT_DIR):
        if file_ == 'None.jpg':
            pass
        else:     
            file_ = file_.split('.jpg')[0]
            file_ = file_[1:-1].split(',')
            file_ = list(map(float,file_))
            file_.append(0)
            print(file_)
            img_db.append(file_)    
    return img_db

```




