---
layout:     post
title:      Machine Learning 常见算法
subtitle:   常见算法总结
date:       2017-11-12
author:     WSS
header-img: img/AI2.jpg
catalog: true
tags:
    - Machine Learning
    - sum
---


## 常见算法 ##

![](http://oyug2kd6x.bkt.clouddn.com//MachineLearning/SumMachineLeaningSum.jpeg)

## 基本概念 ##

所谓机器学习算法就是一个假设集合，用于找到最优模型。机器学习算法可以分为三大类。

### 监督学习 ###

1、监督式学习（Supervised learning），是一个机器学习中的方法，可以由训练资料中学到或建立一个模式（ learning model），并依此模式推测新的实例。训练资料是由输入物件（通常是向量）和预期输出所组成。函数的输出可以是一个连续的值（称为回归分析），或是预测一个分类标签（称作分类）。

2、一个监督式学习者的任务在观察完一些训练范例（输入和预期输出）后，去预测这个函数对任何可能出现的输入的值的输出。要达到此目的，学习者必须以"合理"（见归纳偏向）的方式从现有的资料中一般化到非观察到的情况。在人类和动物感知中，则通常被称为概念学习（concept learning）。

3、监督式学习有两种形态的模型。最一般的，监督式学习产生一个全域模型，会将输入物件对应到预期输出。而另一种，则是将这种对应实作在一个区域模型。（如案例推论及最近邻居法）。为了解决一个给定的监督式学习的问题（手写辨识），必须考虑以下步骤：

1）决定训练资料的范例的形态。在做其它事前，工程师应决定要使用哪种资料为范例。譬如，可能是一个手写字符，或一整个手写的词汇，或一行手写文字。

2）搜集训练资料。这资料须要具有真实世界的特征。所以，可以由人类专家或（机器或传感器的）测量中得到输入物件和其相对应输出。

3）决定学习函数的输入特征的表示法。学习函数的准确度与输入的物件如何表示是有很大的关联度。传统上，输入的物件会被转成一个特征向量，包含了许多关于描述物件的特征。因为*维数灾难*[1]的关系，特征的个数不宜太多，但也要足够大，才能准确的预测输出。

4）决定要学习的函数和其对应的学习算法所使用的数据结构。譬如，工程师可能选择人工神经网络和决策树。

5）完成设计。工程师接着在搜集到的资料上跑学习算法。可以借由将资料跑在资料的子集（称为验证集）或交叉验证（cross-validation）上来调整学习算法的参数。参数调整后，算法可以运行在不同于训练集的测试集上

另外对于监督式学习所使用的词汇则是分类。现著有著各式的分类器，各自都有强项或弱项。分类器的表现很大程度上地跟要被分类的资料特性有关。并没有某一单一分类器可以在所有给定的问题上都表现最好，这被称为‘天下没有白吃的午餐理论’。各式的经验法则被用来比较分类器的表现及寻找会决定分类器表现的资料特性。决定适合某一问题的分类器仍旧是一项艺术，而非科学。

目前最广泛被使用的分类器有`人工神经网络`、`支持向量机`、`最近邻居法`、`高斯混合模型`、`朴素贝叶斯方法`、`决策树`和`径向基函数`分类。


### 无监督学习 ###

1、无监督式学习(Unsupervised Learning )是人工智能网络的一种算法(algorithm)，其目的是去对原始资料进行分类，以便了解资料内部结构。有别于监督式学习网络，无监督式学习网络在学习时并不知道其分类结果是否正确，亦即没有受到监督式增强(告诉它何种学习是正确的)。其特点是仅对此种网络提供输入范例，而它会自动从这些范例中找出其潜在类别规则。当学习完毕并经测试后，也可以将之应用到新的案例上。

2、无监督学习里典型的例子就是聚类了。聚类的目的在于把相似的东西聚在一起，而我们并不关心这一类是什么。因此，一个聚类算法通常只需要知道如何计算相似度就可以开始工作了。


### 无监督学习 ###

如果所有训练数据都有标签，则为有监督学习（supervised learning）。如果数据没有标签，显然就是无监督学习（unsupervised learning）了，也即聚类（clustering）。

目前分类算法的效果还是不错的，但相对来讲，聚类算法就有些惨不忍睹了。确实，无监督学习本身的特点使其难以得到如分类一样近乎完美的结果。这也正如我们在高中做题，答案（标签）是非常重要的，假设两个完全相同的人进入高中，一个正常学习，另一人做的所有题目都没有答案，那么想必第一个人高考会发挥更好，第二个人会发疯。

既然分类如此之好，聚类如此之不靠谱，那为何我们还可以容忍聚类的存在？因为在实际应用中，标签的获取常常需要极大的人工工作量，有时甚至非常困难。例如在自然语言处理（NLP）中，Penn Chinese Treebank在2年里只完成了4000句话的标签……


### 半监督学习 ###


对于半监督学习，其训练数据的一部分是有标签的，另一部分没有标签，而没标签数据的数量常常极大于有标签数据数量（这也是符合现实情况的）。隐藏在半监督学习下的基本规律在于：数据的分布必然不是完全随机的，通过一些有标签数据的局部特征，以及更多没标签数据的整体分布，就可以得到可以接受甚至是非常好的分类结果。（此处大量忽略细节）



>[1]:在很多领域中，如采样、组合数学、机器学习和数据挖掘都有提及到这个名字的现象。这些问题的共同特色是当维数提高时，空间的体积提高太快，因而可用数据变得很稀疏。
>资料参考：[知乎](https://www.zhihu.com/question/23194489/answer/25028661)、[CSDN](http://blog.csdn.net/u011067360/article/details/24735415)、[机器学习算法简洁](http://www.sohu.com/a/204045338_610300)